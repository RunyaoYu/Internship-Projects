{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_assigment2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90bedcb0453847f8abc122ad9ee49541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16107e62835b4468a1d4a4039efbdde7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0d22593d63e546d38d94971669c0d90f",
              "IPY_MODEL_bb566ab7483b4dc68bc2ac28dc559926",
              "IPY_MODEL_9247002e7a6d4a99b23cbff7016c099f"
            ]
          }
        },
        "16107e62835b4468a1d4a4039efbdde7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d22593d63e546d38d94971669c0d90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5e5d26c11de480cb5d2b77601a70af3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  9%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e1c3ad131024c56a391556dcdd1c0fa"
          }
        },
        "bb566ab7483b4dc68bc2ac28dc559926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_28c3000e6d284f52a5b7c15b777319a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfe717ec7671467e8baa0e4507adb938"
          }
        },
        "9247002e7a6d4a99b23cbff7016c099f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ccf872fcc598465cbf82f130c306f234",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9/100 [41:24&lt;6:58:25, 275.89s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40f9b6e64b8a4b218a6d6750f6033267"
          }
        },
        "f5e5d26c11de480cb5d2b77601a70af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e1c3ad131024c56a391556dcdd1c0fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28c3000e6d284f52a5b7c15b777319a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfe717ec7671467e8baa0e4507adb938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccf872fcc598465cbf82f130c306f234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40f9b6e64b8a4b218a6d6750f6033267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwcNpKTZDB7r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import torch.nn.functional as F\n",
        "# from d2l import torch as d2l\n",
        "\n",
        "\n",
        "import glob\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxmPMPMxEUFW",
        "outputId": "244960d9-7c67-4683-ee98-c4c7b9c4e61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "torch.cuda.manual_seed_all(1)\n",
        "torch.backends.cudnn.deterministic=True "
      ],
      "metadata": {
        "id": "fisO4TeeEW9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta = json.load(open('/content/drive/MyDrive/dl_assigment_2/meta.json', 'r'))\n",
        "tokens = meta['tokens']  # 标注有多少个单词\n",
        "num_user = meta['num_user']\n",
        "num_token = len(tokens)"
      ],
      "metadata": {
        "id": "61ncN8Y3Eb5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens.append(\"<pad>\")"
      ],
      "metadata": {
        "id": "EToGvrCQIDon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens.index(\"<pad>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyDG92SNL_53",
        "outputId": "4f9eab7d-a555-4389-f623-2db6e03cb268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13369"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = json.load(open('/content/drive/MyDrive/dl_assigment_2/train.json', 'r'))\n",
        "valid_data = json.load(open('/content/drive/MyDrive/dl_assigment_2/valid.json', 'r'))"
      ],
      "metadata": {
        "id": "DIzYvLPKEdVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "84yBcUosh0u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 0\n",
        "for i in range(len(train_data)):\n",
        "    sample = train_data[i]\n",
        "    token = sample[\"token_id\"]\n",
        "    max_length = max(max_length, len(token))\n",
        "\n",
        "print(max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqV_X34XEfRg",
        "outputId": "cfeb9164-a724-4216-f6a7-1faf704855eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class tweetDataset(Dataset):\n",
        "    def __init__(self, data, max_length, tokens):\n",
        "        self.data = data\n",
        "        self.max_length = max_length\n",
        "        self.tokens = tokens\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = 0\n",
        "        sample = self.data[idx]\n",
        "        val_length = []\n",
        "        for index in [idx]:\n",
        "          sample_single = self.data[index]\n",
        "          sentence = len(sample_single[\"token_id\"])\n",
        "          val_length.append(sentence)\n",
        "\n",
        "        token_id = [sample[\"token_id\"]]\n",
        "        padded_token_id = pad_sequences(token_id, maxlen=self.max_length, padding='post',)\n",
        "        sample['token_id'] = torch.Tensor(padded_token_id[0])\n",
        "        sample[\"val_length\"] = val_length[0]\n",
        "     \n",
        "        return sample"
      ],
      "metadata": {
        "id": "exsVtvaFEh9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tweetDataset(train_data, max_length, tokens)\n",
        "valid_dataset = tweetDataset(valid_data, max_length, tokens)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "cPAyF7yvFvJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_dataloader))\n",
        "\n",
        "print('Sample from train dataloader: ')\n",
        "print('USER ID: ', sample['user_id'])\n",
        "print('TOKEN ID: ', sample['token_id'])\n",
        "print('TOKEN ID shape should be BATCH by LENGTH: ', sample['token_id'].shape)\n",
        "print(\"length:\", sample['val_length'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fq1lwKfF_CW",
        "outputId": "3f5327b9-8e35-49e9-c8f2-e1d44809eaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample from train dataloader: \n",
            "USER ID:  tensor([2, 3])\n",
            "TOKEN ID:  tensor([[ 8039.,  6211.,  6199.,  2495., 11873.,   491.,   565.,  6833., 10048.,\n",
            "          6191.,  4163.,  2795.,  1983.,  6480., 11865.,  8733., 11431.,  7320.,\n",
            "          6920., 12017., 11916., 13021.,   661., 10638., 11888.,   661.,  5870.,\n",
            "          8537.,  7320., 12262.,  6388., 12271.,   491.,  6918.,     0.,     0.,\n",
            "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "             0.,     0.,     0.,     0.,     0.,     0.],\n",
            "        [ 2897., 12017., 10504.,  7815.,  6679.,  9828.,  5636.,  6388.,  7921.,\n",
            "         12017.,  4981., 12017.,  6670.,  4236., 13021., 13060.,  6936., 11874.,\n",
            "          6223., 11087.,  8891.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
            "             0.,     0.,     0.,     0.,     0.,     0.]])\n",
            "TOKEN ID shape should be BATCH by LENGTH:  torch.Size([2, 60])\n",
            "length: tensor([60, 60])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample['token_id'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wnepVbsdyAQ",
        "outputId": "c4df291b-bf25-4939-bdd1-45fcc654014c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 60])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, num_token, num_user, embed_dim, rnn_dim, num_layers):\n",
        "        super(Model, self).__init__()\n",
        "        self.num_token = num_token\n",
        "        self.num_user = num_user\n",
        "        self.embed_dim = embed_dim\n",
        "        self.rnn_dim = rnn_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(num_token, embed_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.atten = nn.MultiheadAttention(rnn_dim, 1, dropout=0.1)\n",
        "\n",
        "        # 将bidirectional设置为True以获取双向循环神经网络\n",
        "        self.rnn = nn.LSTM(embed_dim, rnn_dim, num_layers=num_layers, batch_first=True, bidirectional=False)\n",
        "        self.out_linear = nn.Linear(rnn_dim, num_user)\n",
        "\n",
        "    def forward(self, token_id, val_length):\n",
        "        # inputs的形状是（批量大小，时间步数）\n",
        "        # 因为长短期记忆网络要求其输入的第一个维度是时间维，\n",
        "        # 所以在获得词元表示之前，输入会被转置。\n",
        "        # 输出形状为（时间步数，批量大小，词向量维度）\n",
        "        embeddings = self.embedding(token_id.T)\n",
        "        # embeddings = self.dropout(embeddings)\n",
        "        self.rnn.flatten_parameters()\n",
        "        # 返回上一个隐藏层在不同时间步的隐状态，\n",
        "        # outputs的形状是（时间步数，批量大小，2*隐藏单元数）\n",
        "        embeddings = nn.utils.rnn.pack_padded_sequence(embeddings.permute(1,0,2), val_length, batch_first=True, enforce_sorted=False)\n",
        "        outputs, _ = self.rnn(embeddings)\n",
        "        outputs, _= nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "        result = outputs.permute(1,0,2)\n",
        "        final, _ = self.atten(result, result, result)\n",
        "        # 连结初始和最终时间步的隐状态，作为全连接层的输入，\n",
        "        # 其形状为（批量大小，4*隐藏单元数）\n",
        "        # encoding = torch.cat((final[0], final[-1]), dim=1)\n",
        "        outs = self.out_linear(final[-1])\n",
        "        return outs"
      ],
      "metadata": {
        "id": "htOtyJ5sTZBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "model = Model(num_token, num_user, embed_dim=512, rnn_dim=1158, num_layers=1).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.8e-5, weight_decay=1e-7)"
      ],
      "metadata": {
        "id": "fZSM2O6XfX0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_param = sum(p.numel() for p in model.parameters())\n",
        "print('Number of parameters: {}'.format(num_param))\n",
        "print('[NOTE] Number of parameters SHOULD NOT exceed 20,000,000 (20 million).')\n",
        "pred = model(sample['token_id'].long().to(device), sample['val_length'].to(\"cpu\"))\n",
        "print('Prediction shape would be BATCH X NUM_USER(OUTPUT) : ', pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2aUWtYrfEJG",
        "outputId": "d39ca5a9-fb8f-4798-c58b-bd28e9d03463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 19967392\n",
            "[NOTE] Number of parameters SHOULD NOT exceed 20,000,000 (20 million).\n",
            "Prediction shape would be BATCH X NUM_USER(OUTPUT) :  torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = nn.CrossEntropyLoss()\n",
        "avg_loss = 0.0\n",
        "best_valid_accu = 0.0\n",
        "best_epoch = -1\n",
        "best_model = None\n",
        "num_epoch = 100\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    # start training\n",
        "    for sample in train_dataloader:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = model(sample['token_id'].long().to(device), sample['val_length'].to(\"cpu\"))\n",
        "        # print(pred)\n",
        "\n",
        "        loss = criteria(pred, sample['user_id'].long().to(device))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_loss += loss.item() / len(train_dataloader)\n",
        "\n",
        "    # start validation\n",
        "    correct_cnt = 0.0\n",
        "    data_cnt = 0.0\n",
        "    for sample in valid_dataloader:\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(sample['token_id'].long().to(device), sample['val_length'].to(\"cpu\"))\n",
        "\n",
        "        pred_user_id = torch.argmax(pred, dim=-1)\n",
        "\n",
        "        accu = pred_user_id.detach().cpu() == sample['user_id']\n",
        "\n",
        "        correct_cnt += torch.sum(accu)\n",
        "        data_cnt += sample['token_id'].shape[0]\n",
        "\n",
        "    # calculate best valid accuracy, and save the best model. \n",
        "    curr_valid_accu = (correct_cnt / data_cnt).item()\n",
        "\n",
        "    print('[EPOCH {}] VALID ACCURACY UPDATED: {}'.format(epoch, curr_valid_accu))\n",
        "\n",
        "    best_valid_accu = max(best_valid_accu, curr_valid_accu)\n",
        "    if best_valid_accu == curr_valid_accu:\n",
        "        best_epoch = epoch\n",
        "        best_model = copy.deepcopy(model)\n",
        "        torch.save(best_model.state_dict(), 'best_baseline.pth')\n",
        "        print('[EPOCH {}] BEST VALID ACCURACY UPDATED: {}'.format(epoch, best_valid_accu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335,
          "referenced_widgets": [
            "90bedcb0453847f8abc122ad9ee49541",
            "16107e62835b4468a1d4a4039efbdde7",
            "0d22593d63e546d38d94971669c0d90f",
            "bb566ab7483b4dc68bc2ac28dc559926",
            "9247002e7a6d4a99b23cbff7016c099f",
            "f5e5d26c11de480cb5d2b77601a70af3",
            "0e1c3ad131024c56a391556dcdd1c0fa",
            "28c3000e6d284f52a5b7c15b777319a0",
            "cfe717ec7671467e8baa0e4507adb938",
            "ccf872fcc598465cbf82f130c306f234",
            "40f9b6e64b8a4b218a6d6750f6033267"
          ]
        },
        "id": "g3twsxaDfzAc",
        "outputId": "45d461c1-33a2-4b70-b26c-3f7e3acbe1f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90bedcb0453847f8abc122ad9ee49541",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EPOCH 0] VALID ACCURACY UPDATED: 0.44662922620773315\n",
            "[EPOCH 0] BEST VALID ACCURACY UPDATED: 0.44662922620773315\n",
            "[EPOCH 1] VALID ACCURACY UPDATED: 0.5449438095092773\n",
            "[EPOCH 1] BEST VALID ACCURACY UPDATED: 0.5449438095092773\n",
            "[EPOCH 2] VALID ACCURACY UPDATED: 0.5870786309242249\n",
            "[EPOCH 2] BEST VALID ACCURACY UPDATED: 0.5870786309242249\n",
            "[EPOCH 3] VALID ACCURACY UPDATED: 0.5814606547355652\n",
            "[EPOCH 4] VALID ACCURACY UPDATED: 0.5898876190185547\n",
            "[EPOCH 4] BEST VALID ACCURACY UPDATED: 0.5898876190185547\n",
            "[EPOCH 5] VALID ACCURACY UPDATED: 0.6067415475845337\n",
            "[EPOCH 5] BEST VALID ACCURACY UPDATED: 0.6067415475845337\n",
            "[EPOCH 6] VALID ACCURACY UPDATED: 0.632022500038147\n",
            "[EPOCH 6] BEST VALID ACCURACY UPDATED: 0.632022500038147\n",
            "[EPOCH 7] VALID ACCURACY UPDATED: 0.6151685118675232\n",
            "[EPOCH 8] VALID ACCURACY UPDATED: 0.6348314881324768\n",
            "[EPOCH 8] BEST VALID ACCURACY UPDATED: 0.6348314881324768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "metadata": {
        "id": "pnyefEJwh4KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample['token_id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtT-DX5jtDJ7",
        "outputId": "4acaba9f-f532-477a-d256-6746660a8a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5721.,   434.,  3841.,  7382., 13106., 11370., 11891.,  2727.,  3818.,\n",
              "           491.,   667.,   240., 12017.,   726., 11853., 12089.,  9487.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.],\n",
              "        [ 7815.,  7454., 12017.,  7815.,  4345.,   460.,   491.,  4693.,   687.,\n",
              "         11853., 13171.,  4547., 11908., 12954.,   799.,  8324., 11853.,  1732.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq = torch.tensor([[1,2,0], [3,0,0], [4,5,6]])\n",
        "lens = [2, 1, 3]\n",
        "packed = pack_padded_sequence(seq, lens, batch_first=True, enforce_sorted=False)"
      ],
      "metadata": {
        "id": "DFuo5mSOq4YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = sample['token_id']\n",
        "x_len = [17,18]\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaqlJwvStN9d",
        "outputId": "eb75eb07-be08-454c-f1aa-d94f593e135f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5721.,   434.,  3841.,  7382., 13106., 11370., 11891.,  2727.,  3818.,\n",
              "           491.,   667.,   240., 12017.,   726., 11853., 12089.,  9487.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.],\n",
              "        [ 7815.,  7454., 12017.,  7815.,  4345.,   460.,   491.,  4693.,   687.,\n",
              "         11853., 13171.,  4547., 11908., 12954.,   799.,  8324., 11853.,  1732.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
              "             0.,     0.,     0.,     0.,     0.,     0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " x = nn.utils.rnn.pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        " x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm4rdcZwtGzO",
        "outputId": "8bf60593-c9c9-445c-9bf6-e39de1deb9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([ 7815.,  5721.,  7454.,   434., 12017.,  3841.,  7815.,  7382.,  4345.,\n",
              "        13106.,   460., 11370.,   491., 11891.,  4693.,  2727.,   687.,  3818.,\n",
              "        11853.,   491., 13171.,   667.,  4547.,   240., 11908., 12017., 12954.,\n",
              "          726.,   799., 11853.,  8324., 12089., 11853.,  9487.,  1732.]), batch_sizes=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1]), sorted_indices=tensor([1, 0]), unsorted_indices=tensor([1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Co_thqZetdqK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}